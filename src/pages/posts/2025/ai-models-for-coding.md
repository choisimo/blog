---
title: "코딩용 AI 모델, 어떤 걸 써야 할까?"
date: "2025-01-24"
category: "기술"
tags: ['AI', '개발', 'GPT', 'Claude', 'Gemini', '코딩']
excerpt: "개발자 입장에서 GPT, Claude, Gemini 등 주요 AI 모델들을 실제로 써보고 비교해본 후기"
readTime: "3분"
---

최근에 개발할 때 AI 도움을 많이 받고 있는데, 솔직히 어떤 모델을 써야 할지 헷갈린다. GPT-4o, Claude, Gemini... 각각 뭐가 다른지, 어떨 때 뭘 써야 하는지 정리해보려고 한다.

## 컨텍스트 창이 왜 중요한가?

AI 모델을 고를 때 가장 중요한 건 **컨텍스트 창** 크기다. 간단히 말해서 AI가 한 번에 기억할 수 있는 정보량이다. 

예를 들어, GPT-4o는 32,000 토큰 정도인데, 이게 대략 100페이지 분량이다. 하지만 실제로는 시스템 메시지, 이전 대화 내용 등이 다 포함되니까 실제로 쓸 수 있는 건 더 적다.

여기서 두 가지 접근 방식이 있다:

1. **네이티브 롱 컨텍스트**: Gemini처럼 아예 엄청 큰 컨텍스트 창을 가진 모델 쓰기
2. **RAG (검색 증강 생성)**: 필요한 정보만 골라서 모델에게 주는 방식

개인적으로는 큰 프로젝트 작업할 때 Gemini의 롱 컨텍스트가 정말 편했다. 전체 코드베이스를 한 번에 넣고 "이 프로젝트에서 버그 있는 부분 찾아줘" 하면 된다.

## 각 모델별 특징

### OpenAI GPT 시리즈

- **GPT-4o**: 128,000 토큰, 빠르고 안정적
- **GPT-4.1**: 1,000,000 토큰, 복잡한 작업용
- **추론 모델 (o1, o3)**: 복잡한 논리 작업에 특화

GPT-4o를 가장 많이 쓰는데, 일반적인 코딩 작업에는 충분하다. 다만 ChatGPT로 쓰면 실제 컨텍스트가 API보다 훨씬 작다는 게 아쉽다.

### Anthropic Claude

- **Claude 3.5 Sonnet**: 200,000 토큰, 코딩에 강함
- **Claude 3.7 Sonnet**: 확장 모드에서 64,000 토큰 출력 가능

개인적으로 Claude가 코드 품질이 가장 좋았다. HumanEval 벤치마크에서도 92-93% 정도로 최고 수준이고, 실제로 써봐도 깔끔한 코드를 만들어준다.

### Google Gemini

- **Gemini 1.5 Pro**: 2,000,000 토큰(!)
- **Gemini 2.5 Pro**: 성능 향상 + 에이전트 기능 강화

Gemini의 200만 토큰은 정말 압도적이다. 큰 프로젝트 전체를 한 번에 분석하고 싶을 때는 이걸 쓸 수밖에 없다.

## 실제 성능은 어떨까?

벤치마크 점수를 보면:

- **HumanEval (단순 코드 생성)**: Claude 3.5 Sonnet (92%) > GPT-4o (90%) > Gemini 1.5 Pro (84%)
- **SWE-bench (실제 이슈 해결)**: 이게 더 복잡하다. 같은 모델이라도 어떤 도구와 함께 쓰느냐에 따라 성능이 2배 이상 차이 난다.

예를 들어 GPT-4o가 SWE-bench에서 18%였다가 다른 도구와 함께 쓰니까 38%까지 올라갔다. 결국 모델 자체보다는 어떻게 쓰느냐가 더 중요하다는 뜻이다.

## 언제 뭘 써야 할까?

개인적인 사용 경험을 바탕으로 정리하면:

### 대규모 코드베이스 분석
- **Gemini 2.5 Pro** 추천
- 전체 프로젝트를 한 번에 넣고 리팩토링이나 구조 분석할 때 최고

### 일반적인 코딩, 버그 수정
- **Claude 3.5/3.7 Sonnet** 추천  
- 코드 품질이 가장 좋고, 설명도 깔끔함

### 브레인스토밍, 복잡한 추론
- **GPT-4o/4.1** 추천
- 가장 균형 잡힌 성능, 다양한 주제에 대해 잘 알고 있음

### 빠르고 간단한 작업
- **GPT-4o mini** 나 **Gemini Flash** 추천
- 비용 절약하면서 빠른 응답

## 개발 도구들도 중요하다

사실 요즘은 모델을 직접 쓰기보다는 통합된 도구를 쓰는 경우가 많다:

- **GitHub Copilot**: 에디터에 바로 통합, 여러 모델 혼합 사용
- **Cursor**: 에이전트 기능이 좋다고 들음  
- **Greptile**: 기업용 코드베이스 분석에 특화

이런 도구들이 복잡한 컨텍스트 관리를 대신 해줘서 편하다.

## 앞으로는?

컨텍스트 창이 계속 커지고 있어서, RAG 같은 복잡한 시스템 없이도 모든 정보를 한 번에 넣고 처리할 수 있게 될 것 같다. 

Gemini 2.5 Pro가 복잡한 도구 없이도 간단한 프롬프트만으로 50% 이상의 SWE-bench 점수를 낸 걸 보면, 앞으로는 더 간단해질 것 같다.

물론 비용 문제가 있긴 하다. 긴 컨텍스트는 제곱에 비례해서 비싸지니까. 그래도 Google의 컨텍스트 캐싱 같은 기능들로 점점 해결되고 있다.

## 마무리

결국 "최고의 모델"은 없다. 작업에 따라 적합한 모델이 다르다. 

나는 보통:
- 큰 프로젝트 분석: Gemini
- 일반 코딩: Claude  
- 빠른 질문: GPT-4o

이런 식으로 섞어서 쓰고 있다. 여러분도 직접 써보고 자신에게 맞는 걸 찾아보시길.