name: Backend Build & Deploy (SSH Compose) [DEPRECATED]

# =============================================================================
# DEPRECATED: This workflow is superseded by deploy-blog-workflow.yml
# =============================================================================
#
# This workflow has been deprecated in favor of deploy-blog-workflow.yml which
# provides a more complete deployment with:
#   - GHCR image registry (faster, cached)
#   - Full service stack (postgres, redis, mongodb, qdrant, etc.)
#   - n8n workflow import
#   - Credentials auto-setup
#   - Comprehensive E2E testing
#
# The two workflows had overlapping triggers and caused conflicts.
# Use deploy-blog-workflow.yml for all backend deployments.
#
# To run this workflow manually, uncomment the on: section below.
# =============================================================================

# DISABLED - Use deploy-blog-workflow.yml instead
# on:
#   push:
#     paths:
#       - 'backend/**'
#       - '.github/workflows/backend-deploy.yml'
#     branches: [ main ]
#   workflow_dispatch:

on:
  workflow_dispatch:
    inputs:
      ref:
        description: 'Ref (branch/sha) to deploy'
        required: false
        default: ''
      skip_build:
        description: 'Skip build, only pull and restart (for config changes)'
        required: false
        default: false
        type: boolean

permissions:
  contents: read

concurrency:
  group: backend-deploy-${{ github.ref }}
  cancel-in-progress: true

jobs:
  build-and-deploy:
    runs-on: ubuntu-latest

    env:
      IMAGE_NAME: blog-backend
      IMAGE_TAG: ${{ github.sha }}
      SSH_HOST: ${{ secrets.SSH_HOST }}
      SSH_USER: ${{ secrets.SSH_USER }}
      SSH_PORT: ${{ secrets.SSH_PORT || '22' }}
      REMOTE_DIR: ${{ secrets.REMOTE_DIR }}
      PUBLIC_API_BASE_URL: ${{ secrets.PUBLIC_API_BASE_URL }}
      PUBLIC_FRONTEND_ORIGIN: https://noblog.nodove.com

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          ref: ${{ github.event.inputs.ref || github.ref }}

      - name: Set up Docker Buildx
        if: ${{ github.event.inputs.skip_build != 'true' }}
        uses: docker/setup-buildx-action@v3

      - name: Build backend API image (local load)
        if: ${{ github.event.inputs.skip_build != 'true' }}
        uses: docker/build-push-action@v5
        with:
          context: ./backend
          file: ./backend/Dockerfile
          push: false
          load: true
          tags: ${{ env.IMAGE_NAME }}:${{ env.IMAGE_TAG }}

      - name: Build Terminal Server image
        if: ${{ github.event.inputs.skip_build != 'true' }}
        uses: docker/build-push-action@v5
        with:
          context: ./backend/terminal-server
          file: ./backend/terminal-server/Dockerfile
          push: false
          load: true
          tags: terminal-server:${{ env.IMAGE_TAG }}

      - name: Save images artifact (gzip)
        if: ${{ github.event.inputs.skip_build != 'true' }}
        run: |
          docker save \
            "${IMAGE_NAME}:${IMAGE_TAG}" \
            "terminal-server:${IMAGE_TAG}" \
            | gzip > backend-images.tar.gz
          ls -lh backend-images.tar.gz

      - name: Start ssh-agent and add key
        uses: webfactory/ssh-agent@v0.9.0
        with:
          ssh-private-key: ${{ secrets.SSH_PRIVATE_KEY }}

      - name: Add remote host to known_hosts
        run: |
          mkdir -p ~/.ssh
          ssh-keyscan -p "${SSH_PORT}" -H "${SSH_HOST}" >> ~/.ssh/known_hosts

      - name: Prepare .env from secret
        run: |
          if [ -z "${{ secrets.BACKEND_ENV_FILE }}" ]; then
            echo "BACKEND_ENV_FILE secret is missing." >&2; exit 1;
          fi
          printf "%s" "${{ secrets.BACKEND_ENV_FILE }}" > /tmp/backend.env

      - name: Upload artifacts to remote
        run: |
          test -n "${REMOTE_DIR}" || { echo "REMOTE_DIR secret is missing" >&2; exit 1; }
          ssh -p "${SSH_PORT}" "${SSH_USER}@${SSH_HOST}" "mkdir -p ${REMOTE_DIR} ${REMOTE_DIR}/ssl"

          # Upload images (if built)
          if [ -f backend-images.tar.gz ]; then
            scp -P "${SSH_PORT}" backend-images.tar.gz "${SSH_USER}@${SSH_HOST}:${REMOTE_DIR}/"
          fi

          # Upload config files (use consolidated nginx config with SSL)
          scp -P "${SSH_PORT}" backend/nginx/nginx.conf "${SSH_USER}@${SSH_HOST}:${REMOTE_DIR}/nginx.conf"
          scp -P "${SSH_PORT}" /tmp/backend.env "${SSH_USER}@${SSH_HOST}:${REMOTE_DIR}/.env"
          
          # Upload SSL certificate generation script
          scp -P "${SSH_PORT}" backend/scripts/generate-ssl-cert.sh "${SSH_USER}@${SSH_HOST}:${REMOTE_DIR}/generate-ssl-cert.sh"

      - name: Deploy full stack on remote
        env:
          SHA: ${{ github.sha }}
          SKIP_BUILD: ${{ github.event.inputs.skip_build }}
        run: |
          ssh -p "${SSH_PORT}" "${SSH_USER}@${SSH_HOST}" "REMOTE_DIR='${REMOTE_DIR}' SHA='${SHA}' bash -s" <<'REMOTE_EOF'
          set -euo pipefail
          DC="docker compose"
          if ! $DC version >/dev/null 2>&1; then DC="docker-compose"; fi
          cd "${REMOTE_DIR}"
          IMAGE_TAG="${SHA}"
          IMAGE_NAME="blog-backend"

          # Load images if present
          if [ -f backend-images.tar.gz ]; then
            echo "Loading images on remote..."
            gzip -dc backend-images.tar.gz | docker load
            rm -f backend-images.tar.gz
          fi

          # Generate SSL certificate if not exists
          echo "Checking SSL certificate..."
          chmod +x generate-ssl-cert.sh 2>/dev/null || true
          ./generate-ssl-cert.sh ./ssl

          # =====================================================
          # Stop conflicting services before starting new ones
          # =====================================================
          echo ""
          echo "=== Cleaning Up Conflicting Services ==="
          
          # Stop any existing compose projects that might conflict
          for compose_file in compose.runtime.yml docker-compose.yml docker-compose.blog-workflow.yml; do
            if [ -f "$compose_file" ]; then
              echo "Stopping services from $compose_file..."
              $DC -f "$compose_file" down --remove-orphans 2>/dev/null || true
            fi
          done
          
          # Stop any containers using conflicting ports
          echo "Checking for port conflicts..."
          for port in 80 443 8080 8443 8180 8100; do
            CONTAINER=$(docker ps --filter "publish=$port" --format "{{.Names}}" 2>/dev/null | head -1)
            if [ -n "$CONTAINER" ]; then
              echo "Stopping container using port $port: $CONTAINER"
              docker stop "$CONTAINER" 2>/dev/null || true
              docker rm -f "$CONTAINER" 2>/dev/null || true
            fi
          done
          
          # Cleanup dangling networks
          docker network prune -f 2>/dev/null || true

          # Generate runtime compose file with SSL support
          cat > compose.runtime.yml <<'YML'
          # =======================================================================
          # Runtime Compose - Backend Services for n8n Integration
          # =======================================================================
          # NOTE: Primary API Gateway is Cloudflare Workers (workers/api-gateway/).
          # This compose file is for backend services and n8n workflow integration.
          #
          # Cloudflare Workers → Server:8080 → nginx → Internal Services
          # OR
          # Cloudflare (Full SSL) → Server:8443 → nginx (SSL) → Internal Services
          #
          # Domains:
          #   blog-b.nodove.com  → Backend API, Terminal
          #   blog-bw.nodove.com → n8n Workflow Engine
          #
          # Ports:
          #   80/8080  - HTTP (health checks, internal)
          #   443/8443 - HTTPS (Cloudflare Full SSL)
          # =======================================================================

          services:
            # Nginx Reverse Proxy with SSL
            nginx:
              image: nginx:alpine
              depends_on:
                api:
                  condition: service_started
                n8n:
                  condition: service_started
              ports:
                - "80:80"       # HTTP
                - "8080:80"     # HTTP alternative
                - "443:443"     # HTTPS
                - "8443:8443"   # HTTPS alternative (Cloudflare Origin -> 8443)
              volumes:
                - ./nginx.conf:/etc/nginx/conf.d/default.conf:ro
                - ./ssl:/etc/nginx/ssl:ro
              networks:
                - backend
              restart: unless-stopped
              healthcheck:
                test: ["CMD", "wget", "-q", "--spider", "http://localhost/health"]
                interval: 30s
                timeout: 10s
                retries: 3
                start_period: 10s

            # Backend API Server
            api:
              image: blog-backend:IMAGE_TAG_PLACEHOLDER
              env_file: .env
              environment:
                - APP_ENV=production
                - HOST=0.0.0.0
                - PORT=5080
                - N8N_BASE_URL=http://n8n:5678
                - AI_PROVIDER=n8n
              expose:
                - "5080"
              networks:
                - backend
              restart: unless-stopped
              healthcheck:
                test: ["CMD", "wget", "-q", "--spider", "http://localhost:5080/api/v1/healthz"]
                interval: 30s
                timeout: 10s
                retries: 5
                start_period: 60s

            # TEI Embedding Server (internal only, no host port binding)
            embedding-server:
              image: ghcr.io/huggingface/text-embeddings-inference:cpu-latest
              command: --model-id sentence-transformers/all-MiniLM-L6-v2
              expose:
                - "80"
              volumes:
                - tei-data:/data
              networks:
                - backend
              restart: unless-stopped

            # ChromaDB (internal only, no host port binding)
            chromadb:
              image: chromadb/chroma:0.5.23
              environment:
                - IS_PERSISTENT=TRUE
                - PERSIST_DIRECTORY=/chroma/chroma
                - ANONYMIZED_TELEMETRY=FALSE
              expose:
                - "8000"
              volumes:
                - chroma-data:/chroma/chroma
              networks:
                - backend
              restart: unless-stopped
              healthcheck:
                test: ["CMD", "wget", "-q", "--spider", "http://localhost:8000/api/v1/heartbeat"]
                interval: 30s
                timeout: 10s
                retries: 5
                start_period: 60s

            # Terminal Server
            terminal-server:
              image: terminal-server:IMAGE_TAG_PLACEHOLDER
              environment:
                - ORIGIN_SECRET_KEY=${ORIGIN_SECRET_KEY:-default-secret-change-me}
                - SANDBOX_IMAGE=${SANDBOX_IMAGE:-alpine:latest}
              expose:
                - "8080"
              volumes:
                - /var/run/docker.sock:/var/run/docker.sock:ro
              networks:
                - backend
              restart: unless-stopped

            # n8n Workflow Engine (blog-bw.nodove.com) - Complex AI Workflows
            # NOTE: Simple AI API requests are handled by Cloudflare Workers (ai-check-gateway).
            n8n:
              image: n8nio/n8n:latest
              env_file: .env
              environment:
                - N8N_HOST=blog-bw.nodove.com
                - N8N_PORT=5678
                - N8N_PROTOCOL=https
                - WEBHOOK_URL=https://blog-bw.nodove.com/
                - N8N_EDITOR_BASE_URL=https://blog-bw.nodove.com/
                - GENERIC_TIMEZONE=Asia/Seoul
                - TZ=Asia/Seoul
              expose:
                - "5678"
              volumes:
                - n8n-data:/home/node/.n8n
              networks:
                - backend
              restart: unless-stopped
              healthcheck:
                test: ["CMD", "wget", "-q", "--spider", "http://localhost:5678/healthz"]
                interval: 30s
                timeout: 10s
                retries: 5
                start_period: 30s

          networks:
            backend:
              driver: bridge

          volumes:
            tei-data:
            chroma-data:
            n8n-data:
          YML

          # Replace image tag placeholder
          sed -i "s/IMAGE_TAG_PLACEHOLDER/${IMAGE_TAG}/g" compose.runtime.yml

          echo "Bringing up full stack..."
          $DC -f compose.runtime.yml up -d --remove-orphans

          # Force nginx to reload upstream DNS after API container is recreated
          echo "Reloading nginx to refresh upstream DNS..."
          sleep 5
          $DC -f compose.runtime.yml exec -T nginx nginx -s reload 2>/dev/null || \
            $DC -f compose.runtime.yml restart nginx

          # Wait for services via nginx (port 8080 on host - HTTP)
          echo "Waiting for nginx to be ready (HTTP)..."
          for i in $(seq 1 30); do
            if curl -fsS http://localhost:8080/health >/dev/null 2>&1; then
              echo "nginx HTTP Health OK"
              break
            fi
            echo "nginx Retry $i/30"; sleep 2;
          done

          # Wait for nginx HTTPS
          echo "Waiting for nginx to be ready (HTTPS)..."
          for i in $(seq 1 30); do
            if curl -fsS --insecure https://localhost:8443/health >/dev/null 2>&1; then
              echo "nginx HTTPS Health OK"
              break
            fi
            echo "nginx HTTPS Retry $i/30"; sleep 2;
          done

          echo "Waiting for API health check via nginx..."
          for i in $(seq 1 60); do
            if curl -fsS http://localhost:8080/api/v1/healthz >/dev/null 2>&1; then
              echo "API Health OK"
              break
            fi
            echo "API Retry $i/60"; sleep 2;
          done

          echo "Waiting for n8n health check..."
          for i in $(seq 1 30); do
            if curl -fsS http://localhost:5678/healthz >/dev/null 2>&1; then
              echo "n8n Health OK"
              break
            fi
            echo "n8n Retry $i/30"; sleep 2;
          done

          # Final status
          echo ""
          echo "=== Service Status ==="
          $DC -f compose.runtime.yml ps

          # Verify critical services are running via nginx
          if ! curl -fsS http://localhost:8080/api/v1/healthz >/dev/null 2>&1; then
            echo "FATAL: API health check failed"
            echo "--- nginx logs ---"
            $DC -f compose.runtime.yml logs --no-color nginx | tail -n 30
            echo "--- api logs ---"
            $DC -f compose.runtime.yml logs --no-color api | tail -n 100
            exit 1
          fi

          # Verify SSL is working
          if curl -fsS --insecure https://localhost:8443/health 2>&1 | grep -q '"ssl":true'; then
            echo "SSL verification OK"
          else
            echo "WARNING: SSL health check returned unexpected response"
          fi

          echo ""
          echo "Deployment successful!"
          echo "HTTP:  http://localhost:8080"
          echo "HTTPS: https://localhost:8443"
          REMOTE_EOF

      - name: External health check (public domain)
        if: ${{ env.PUBLIC_API_BASE_URL != '' }}
        continue-on-error: true
        run: |
          echo "Checking public health at ${PUBLIC_API_BASE_URL}/api/v1/healthz ..."
          for i in $(seq 1 30); do
            if curl -fsS "${PUBLIC_API_BASE_URL}/api/v1/healthz" >/dev/null; then
              echo "Public health OK"; exit 0;
            fi
            echo "Retry $i/30"; sleep 2;
          done
          echo "⚠️ Public health check failed at ${PUBLIC_API_BASE_URL}/api/v1/healthz"
          echo "This may indicate Cloudflare Workers or firewall issues."
          exit 1

      - name: Verify public runtime config
        if: ${{ env.PUBLIC_API_BASE_URL != '' }}
        continue-on-error: true
        run: |
          echo "Fetching ${PUBLIC_API_BASE_URL}/api/v1/public/config"
          cfg=$(curl -fsS "${PUBLIC_API_BASE_URL}/api/v1/public/config")
          echo "$cfg"
          echo "$cfg" | grep -q '"ok":\s*true' || { echo 'Config ok=false' >&2; exit 1; }
          echo "$cfg" | grep -q "\"apiBaseUrl\":\s*\"${PUBLIC_API_BASE_URL}\"" || { echo 'apiBaseUrl mismatch' >&2; exit 1; }

      - name: Check CORS header for frontend origin
        if: ${{ env.PUBLIC_API_BASE_URL != '' }}
        continue-on-error: true
        run: |
          echo "Checking CORS for origin ${PUBLIC_FRONTEND_ORIGIN}"
          headers=$(curl -fsS -D - -o /dev/null -H "Origin: ${PUBLIC_FRONTEND_ORIGIN}" "${PUBLIC_API_BASE_URL}/api/v1/healthz")
          echo "$headers"
          printf "%s" "$headers" | awk 'tolower($0) ~ /^access-control-allow-origin:/ {print}' | grep -q "${PUBLIC_FRONTEND_ORIGIN}" || {
            echo "CORS header missing or mismatched for origin ${PUBLIC_FRONTEND_ORIGIN}" >&2; exit 1; }

      - name: Verify AI Gateway via public endpoint
        if: ${{ env.PUBLIC_API_BASE_URL != '' }}
        continue-on-error: true
        run: |
          echo "Checking AI endpoint via ${PUBLIC_API_BASE_URL}/api/v1/ai/health ..."
          echo "NOTE: Primary AI API is now handled by Cloudflare Workers (ai-check-gateway)."
          response=$(curl -fsS "${PUBLIC_API_BASE_URL}/api/v1/ai/health" 2>&1 || echo '{"error":"endpoint not found"}')
          echo "$response"
          echo "AI endpoint check completed (check logs above for status)"
