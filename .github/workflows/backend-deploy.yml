name: Backend Build & Deploy (SSH Compose)

# =============================================================================
# Full Stack Deployment with Cloudflare Workers + LiteLLM AI Gateway
# =============================================================================
# Architecture:
#   Cloudflare Workers -> Server:8080 -> nginx -> api -> litellm -> LLM APIs
#
# Services deployed:
#   - nginx: Reverse proxy (exposed on port 8080)
#   - api: Node.js backend (built from Dockerfile)
#   - litellm: AI Gateway for multiple LLM providers
#   - embedding-server: TEI for RAG
#   - chromadb: Vector database
#   - terminal-server: Docker PTY server
#
# Note: Cloudflare Workers (api-gateway) is deployed separately via workers workflow
#
# Required secrets:
#   - SSH_HOST, SSH_USER, SSH_PRIVATE_KEY, SSH_PORT (optional)
#   - REMOTE_DIR: Remote deployment directory
#   - BACKEND_ENV_FILE: Full .env file contents
#   - PUBLIC_API_BASE_URL: Public API URL for health checks
# =============================================================================

on:
  push:
    paths:
      - 'backend/**'
      - '.github/workflows/backend-deploy.yml'
    branches: [ main ]
  workflow_dispatch:
    inputs:
      ref:
        description: 'Ref (branch/sha) to deploy'
        required: false
        default: ''
      skip_build:
        description: 'Skip build, only pull and restart (for config changes)'
        required: false
        default: false
        type: boolean

permissions:
  contents: read

concurrency:
  group: backend-deploy-${{ github.ref }}
  cancel-in-progress: true

jobs:
  build-and-deploy:
    runs-on: ubuntu-latest

    env:
      IMAGE_NAME: blog-backend
      IMAGE_TAG: ${{ github.sha }}
      SSH_HOST: ${{ secrets.SSH_HOST }}
      SSH_USER: ${{ secrets.SSH_USER }}
      SSH_PORT: ${{ secrets.SSH_PORT || '22' }}
      REMOTE_DIR: ${{ secrets.REMOTE_DIR }}
      PUBLIC_API_BASE_URL: ${{ secrets.PUBLIC_API_BASE_URL }}
      PUBLIC_FRONTEND_ORIGIN: https://noblog.nodove.com

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          ref: ${{ github.event.inputs.ref || github.ref }}

      - name: Set up Docker Buildx
        if: ${{ github.event.inputs.skip_build != 'true' }}
        uses: docker/setup-buildx-action@v3

      - name: Build backend API image (local load)
        if: ${{ github.event.inputs.skip_build != 'true' }}
        uses: docker/build-push-action@v5
        with:
          context: ./backend
          file: ./backend/Dockerfile
          push: false
          load: true
          tags: ${{ env.IMAGE_NAME }}:${{ env.IMAGE_TAG }}

      - name: Build Terminal Server image
        if: ${{ github.event.inputs.skip_build != 'true' }}
        uses: docker/build-push-action@v5
        with:
          context: ./backend/terminal-server
          file: ./backend/terminal-server/Dockerfile
          push: false
          load: true
          tags: terminal-server:${{ env.IMAGE_TAG }}

      - name: Save images artifact (gzip)
        if: ${{ github.event.inputs.skip_build != 'true' }}
        run: |
          docker save \
            "${IMAGE_NAME}:${IMAGE_TAG}" \
            "terminal-server:${IMAGE_TAG}" \
            | gzip > backend-images.tar.gz
          ls -lh backend-images.tar.gz

      - name: Start ssh-agent and add key
        uses: webfactory/ssh-agent@v0.9.0
        with:
          ssh-private-key: ${{ secrets.SSH_PRIVATE_KEY }}

      - name: Add remote host to known_hosts
        run: |
          mkdir -p ~/.ssh
          ssh-keyscan -p "${SSH_PORT}" -H "${SSH_HOST}" >> ~/.ssh/known_hosts

      - name: Prepare .env from secret
        run: |
          if [ -z "${{ secrets.BACKEND_ENV_FILE }}" ]; then
            echo "BACKEND_ENV_FILE secret is missing." >&2; exit 1;
          fi
          printf "%s" "${{ secrets.BACKEND_ENV_FILE }}" > /tmp/backend.env

      - name: Upload artifacts to remote
        run: |
          test -n "${REMOTE_DIR}" || { echo "REMOTE_DIR secret is missing" >&2; exit 1; }
          ssh -p "${SSH_PORT}" "${SSH_USER}@${SSH_HOST}" "mkdir -p ${REMOTE_DIR}"

          # Upload images (if built)
          if [ -f backend-images.tar.gz ]; then
            scp -P "${SSH_PORT}" backend-images.tar.gz "${SSH_USER}@${SSH_HOST}:${REMOTE_DIR}/"
          fi

          # Upload config files (use consolidated nginx config)
          scp -P "${SSH_PORT}" backend/nginx/nginx.conf "${SSH_USER}@${SSH_HOST}:${REMOTE_DIR}/nginx.conf"
          scp -P "${SSH_PORT}" /tmp/backend.env "${SSH_USER}@${SSH_HOST}:${REMOTE_DIR}/.env"

          # Upload LiteLLM config if exists
          if [ -f backend/litellm_config.yaml ]; then
            scp -P "${SSH_PORT}" backend/litellm_config.yaml "${SSH_USER}@${SSH_HOST}:${REMOTE_DIR}/litellm_config.yaml"
          fi

      - name: Deploy full stack on remote
        env:
          SHA: ${{ github.sha }}
          SKIP_BUILD: ${{ github.event.inputs.skip_build }}
        run: |
          ssh -p "${SSH_PORT}" "${SSH_USER}@${SSH_HOST}" "REMOTE_DIR='${REMOTE_DIR}' SHA='${SHA}' bash -s" <<'REMOTE_EOF'
          set -euo pipefail
          DC="docker compose"
          if ! $DC version >/dev/null 2>&1; then DC="docker-compose"; fi
          cd "${REMOTE_DIR}"
          IMAGE_TAG="${SHA}"
          IMAGE_NAME="blog-backend"

          # Load images if present
          if [ -f backend-images.tar.gz ]; then
            echo "Loading images on remote..."
            gzip -dc backend-images.tar.gz | docker load
            rm -f backend-images.tar.gz
          fi

          # Generate runtime compose file with Cloudflare Workers architecture
          cat > compose.runtime.yml <<'YML'
          # =======================================================================
          # Runtime Compose - Cloudflare Workers + LiteLLM AI Gateway
          # =======================================================================
          # Cloudflare Workers → Server:8080 → nginx → Internal Services
          #
          # Routes:
          #   /api/*       → api:5080
          #   /ai/*        → litellm:4000
          #   /terminal/*  → terminal-server:8080
          # =======================================================================

          services:
            # Nginx Reverse Proxy (Entry Point from Cloudflare Workers)
            nginx:
              image: nginx:alpine
              depends_on:
                api:
                  condition: service_started
              ports:
                - "8080:80"  # Exposed to Cloudflare Workers
              expose:
                - "80"
              volumes:
                - ./nginx.conf:/etc/nginx/conf.d/default.conf:ro
              networks:
                - backend
              restart: unless-stopped
              healthcheck:
                test: ["CMD", "wget", "-q", "--spider", "http://localhost/health"]
                interval: 30s
                timeout: 10s
                retries: 3
                start_period: 10s

            # Backend API Server
            api:
              image: blog-backend:IMAGE_TAG_PLACEHOLDER
              env_file: .env
              environment:
                - APP_ENV=production
                - HOST=0.0.0.0
                - PORT=5080
                - LITELLM_BASE_URL=http://litellm:4000
                - AI_PROVIDER=litellm
              expose:
                - "5080"
              networks:
                - backend
              restart: unless-stopped
              healthcheck:
                test: ["CMD", "wget", "-q", "--spider", "http://localhost:5080/api/v1/healthz"]
                interval: 30s
                timeout: 10s
                retries: 5
                start_period: 60s

            # LiteLLM AI Gateway
            litellm:
              image: ghcr.io/berriai/litellm:main-latest
              env_file: .env
              environment:
                - LITELLM_MASTER_KEY=${LITELLM_MASTER_KEY:-sk-1234}
                - LITELLM_LOG_LEVEL=INFO
                # Disable database features - we use D1 for usage tracking
                - DISABLE_SPEND_LOGS=true
                - DATABASE_URL=
              expose:
                - "4000"
              volumes:
                - ./litellm_config.yaml:/app/config.yaml:ro
              command: ["--config", "/app/config.yaml", "--port", "4000"]
              networks:
                - backend
              restart: unless-stopped
              healthcheck:
                test: ["CMD", "wget", "-q", "--spider", "http://localhost:4000/health"]
                interval: 30s
                timeout: 10s
                retries: 5
                start_period: 30s

            # TEI Embedding Server
            embedding-server:
              image: ghcr.io/huggingface/text-embeddings-inference:cpu-1.2.3
              command: --model-id sentence-transformers/all-MiniLM-L6-v2
              ports:
                - "127.0.0.1:8180:80"
              volumes:
                - tei-data:/data
              networks:
                - backend
              restart: unless-stopped

            # ChromaDB
            chromadb:
              image: chromadb/chroma:0.5.23
              environment:
                - IS_PERSISTENT=TRUE
                - PERSIST_DIRECTORY=/chroma/chroma
                - ANONYMIZED_TELEMETRY=FALSE
              ports:
                - "127.0.0.1:8100:8000"
              volumes:
                - chroma-data:/chroma/chroma
              networks:
                - backend
              restart: unless-stopped
              healthcheck:
                test: ["CMD", "wget", "-q", "--spider", "http://localhost:8000/api/v1/heartbeat"]
                interval: 30s
                timeout: 10s
                retries: 5
                start_period: 60s

            # Terminal Server
            terminal-server:
              image: terminal-server:IMAGE_TAG_PLACEHOLDER
              environment:
                - ORIGIN_SECRET_KEY=${ORIGIN_SECRET_KEY:-default-secret-change-me}
                - SANDBOX_IMAGE=${SANDBOX_IMAGE:-alpine:latest}
              expose:
                - "8080"
              volumes:
                - /var/run/docker.sock:/var/run/docker.sock:ro
              networks:
                - backend
              restart: unless-stopped

          networks:
            backend:
              driver: bridge

          volumes:
            tei-data:
            chroma-data:
          YML

          # Replace image tag placeholder
          sed -i "s/IMAGE_TAG_PLACEHOLDER/${IMAGE_TAG}/g" compose.runtime.yml

          echo "Bringing up full stack..."
          $DC -f compose.runtime.yml up -d --remove-orphans

          # Force nginx to reload upstream DNS after API container is recreated
          echo "Reloading nginx to refresh upstream DNS..."
          sleep 5
          $DC -f compose.runtime.yml exec -T nginx nginx -s reload 2>/dev/null || \
            $DC -f compose.runtime.yml restart nginx

          # Wait for services via nginx (port 8080 on host)
          echo "Waiting for nginx to be ready..."
          for i in $(seq 1 30); do
            if curl -fsS http://localhost:8080/health >/dev/null 2>&1; then
              echo "nginx Health OK"
              break
            fi
            echo "nginx Retry $i/30"; sleep 2;
          done

          echo "Waiting for API health check via nginx..."
          for i in $(seq 1 60); do
            if curl -fsS http://localhost:8080/api/v1/healthz >/dev/null 2>&1; then
              echo "API Health OK"
              break
            fi
            echo "API Retry $i/60"; sleep 2;
          done

          echo "Waiting for LiteLLM health check..."
          for i in $(seq 1 30); do
            if curl -fsS http://localhost:8080/litellm/health >/dev/null 2>&1; then
              echo "LiteLLM Health OK"
              break
            fi
            echo "LiteLLM Retry $i/30"; sleep 2;
          done

          # Final status
          echo ""
          echo "=== Service Status ==="
          $DC -f compose.runtime.yml ps

          # Verify critical services are running via nginx
          if ! curl -fsS http://localhost:8080/api/v1/healthz >/dev/null 2>&1; then
            echo "FATAL: API health check failed"
            echo "--- nginx logs ---"
            $DC -f compose.runtime.yml logs --no-color nginx | tail -n 30
            echo "--- api logs ---"
            $DC -f compose.runtime.yml logs --no-color api | tail -n 100
            exit 1
          fi

          echo ""
          echo "Deployment successful!"
          REMOTE_EOF

      - name: External health check (public domain)
        if: ${{ env.PUBLIC_API_BASE_URL != '' }}
        continue-on-error: true
        run: |
          echo "Checking public health at ${PUBLIC_API_BASE_URL}/api/v1/healthz ..."
          for i in $(seq 1 30); do
            if curl -fsS "${PUBLIC_API_BASE_URL}/api/v1/healthz" >/dev/null; then
              echo "Public health OK"; exit 0;
            fi
            echo "Retry $i/30"; sleep 2;
          done
          echo "⚠️ Public health check failed at ${PUBLIC_API_BASE_URL}/api/v1/healthz"
          echo "This may indicate Cloudflare Workers or firewall issues."
          exit 1

      - name: Verify public runtime config
        if: ${{ env.PUBLIC_API_BASE_URL != '' }}
        continue-on-error: true
        run: |
          echo "Fetching ${PUBLIC_API_BASE_URL}/api/v1/public/config"
          cfg=$(curl -fsS "${PUBLIC_API_BASE_URL}/api/v1/public/config")
          echo "$cfg"
          echo "$cfg" | grep -q '"ok":\s*true' || { echo 'Config ok=false' >&2; exit 1; }
          echo "$cfg" | grep -q "\"apiBaseUrl\":\s*\"${PUBLIC_API_BASE_URL}\"" || { echo 'apiBaseUrl mismatch' >&2; exit 1; }

      - name: Check CORS header for frontend origin
        if: ${{ env.PUBLIC_API_BASE_URL != '' }}
        continue-on-error: true
        run: |
          echo "Checking CORS for origin ${PUBLIC_FRONTEND_ORIGIN}"
          headers=$(curl -fsS -D - -o /dev/null -H "Origin: ${PUBLIC_FRONTEND_ORIGIN}" "${PUBLIC_API_BASE_URL}/api/v1/healthz")
          echo "$headers"
          printf "%s" "$headers" | awk 'tolower($0) ~ /^access-control-allow-origin:/ {print}' | grep -q "${PUBLIC_FRONTEND_ORIGIN}" || {
            echo "CORS header missing or mismatched for origin ${PUBLIC_FRONTEND_ORIGIN}" >&2; exit 1; }

      - name: Verify AI Gateway via public endpoint
        if: ${{ env.PUBLIC_API_BASE_URL != '' }}
        continue-on-error: true
        run: |
          echo "Checking AI Gateway integration via ${PUBLIC_API_BASE_URL}/api/v1/ai/health ..."
          response=$(curl -fsS "${PUBLIC_API_BASE_URL}/api/v1/ai/health" 2>&1 || echo '{"error":"endpoint not found"}')
          echo "$response"
          echo "AI Gateway public check completed (check logs above for status)"
