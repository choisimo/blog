---
title: "개인화된 가독성: 텍스트를 넘어 이해를 설계하다"
date: "2026-01-25"
category: "Essay"
tags: ["UX", "AI", "Interaction Design", "Readability"]
excerpt: "도구는 차가울지 몰라도, 그 도구가 전하는 이해는 따뜻해야 합니다. 사용자의 맥락에 맞춰 숨 쉬는 문서를 만드는 기술적 여정에 대하여."
readTime: "6분"
---

누군가 작성한 상세한 기술 문서를 읽으며, 정작 "그래서 이게 우리 서비스에 무슨 의미인데?"라고 되물어본 적이 있으신가요? 혹은 기획서의 화려한 용어들 사이에서 "그래서 DB 스키마를 어떻게 짜라는 거지?" 하며 막막해했던 경험은요?

우리는 매일 수많은 텍스트를 생산하고 소비하지만, 슬프게도 그 안에서 서로의 맥락은 자주 휘발됩니다. 개발자가 쓴 ‘동시성 제어’라는 단어는 기획자에게 그저 어려운 숙제처럼 느껴지고, 기획자가 쓴 ‘사용자 감동’이라는 단어는 개발자에게 추상적인 구호로 남곤 하죠.

오늘 이야기하고 싶은 것은, 바로 이 **'이해의 간극'을 메우는 기술**에 대한 것입니다. 단순히 글을 요약해주는 것을 넘어, 읽는 사람의 마음과 배경에 맞춰 형태를 바꾸는 **'개인화된 가독성(Personalized Readability)'**이라는 개념을 설계해보려 합니다.

## 문서를 바라보는 세 가지 렌즈

이 거대한 틈을 메우기 위해, 저는 세 가지의 사용자 경험(UX) 장치를 제안합니다. 이것은 단순한 기능이 아니라, 사용자를 배려하는 마음을 인터페이스로 구현한 것입니다.

첫 번째는 **'렌즈(Lens Concept)'**입니다.
마치 안경을 바꿔 쓰듯, 문서를 바라보는 관점을 전환하는 것입니다. 개발자에게는 치열한 "동시성 제어(Concurrency Control/Locking)"로 보이는 단어가, 기획자의 렌즈를 끼는 순간 "안정적인 동시 접속 처리"라는 비즈니스 언어로 치환됩니다. 이것은 단순한 번역이 아닙니다. 문맥의 보존이자, 상대방의 언어로 말을 걸어주는 배려입니다.

두 번째는 **'동적 초점(Dynamic Focus)'**입니다.
우리는 어두운 방에서 손전등을 비추듯 정보를 탐색합니다. 그런데 이 손전등이 내 마음을 읽는다면 어떨까요? 사용자가 어제 주로 React 문서를 봤거나, 평소 백엔드 코드보다는 프론트엔드 최적화에 관심이 많았다면, 시스템은 이를 기억합니다. 그리고 RAG(검색 증강 생성) 기술을 통해, 긴 문서 안에서도 그 사용자에게 가장 필요한 정보만을 하이라이트하여 보여줍니다. 정보의 홍수 속에서 길을 잃지 않게 해주는 나침반인 셈이죠.

세 번째는 **'점진적 드러냄(Adaptive Detail)'**입니다.
처음부터 모든 기계적인 디테일을 쏟아붓는 것은 폭력적일 수 있습니다. 처음에는 숲을 보여주고, 사용자가 관심을 보이며 다가갈 때 나무를 보여주는 것. 기획 단계에서는 큰 흐름을, 구현 단계에서는 구체적인 API 스펙을 보여주는 'Progressive Disclosure'는 인지 부하를 줄이는 가장 우아한 설계입니다.

## 무대 뒤의 오케스트라: 기술 아키텍처

이 감성적인 경험을 실제로 구현하기 위해서는 무대 뒤에서 치밀하게 돌아가는 기술의 톱니바퀴들이 필요합니다. 마법처럼 보이지만, 사실은 견고한 공학적 설계 위에서 춤추는 기능들이죠.

가장 먼저 구축해야 할 기반은 **'Vector Profile 기반의 Context Injection'**입니다.
사용자가 화면 상단의 [CTO Mode] 버튼을 클릭하는 그 짧은 순간, 시스템 내부에서는 역동적인 변화가 일어납니다. 단순히 정적인 프로필 JSON을 넘기는 게 아닙니다. 시스템 프롬프트(System Prompt) 자체가 실시간으로 교체되는 것입니다.

```yaml
# Dynamic System Prompt Example
role: "Technical Translator"
instruction: "Rewrite the following markdown for a senior software engineer. Focus on API design and scalability."
```

마치 지휘자가 연주자들에게 "지금부터는 웅장하게!"라고 지시를 내리듯, AI에게 현재 사용자의 페르소나를 주입합니다. 그러면 AI는 같은 원문을 보고도 전혀 다른, 그 사람만을 위한 글을 써 내려가기 시작합니다.

하지만 모든 요청을 매번 AI가 새로 쓴다면 속도도 느리고 비용도 만만치 않을 겁니다. 여기서 **'Semantic Caching'**이라는 영리한 전략이 등장합니다.
우리는 Redis 같은 고성능 저장소를 활용해, 자주 요청되는 'CTO 버전', '주니어 개발자 버전'의 변환 결과를 미리 저장해둡니다. 누군가 이미 걸어간 길이라면, 굳이 다시 계산할 필요 없이 그 결과를 0.1초 만에 꺼내어 보여주는 것이죠. 물론, "React는 잘하지만 Vue는 처음인 사용자"처럼 아주 특수한 경우에는 실시간 스트리밍을 통해 맞춤형 콘텐츠를 생성하는 하이브리드 전략을 취합니다.

마지막으로, 이 모든 텍스트가 화면에 그려질 때 레이아웃이 깨지지 않도록 하는 것이 중요합니다. 단순히 텍스트만 갈아 끼우는 게 아니라, 원문의 구조를 **Markdown AST(Abstract Syntax Tree)**로 파싱하여 관리합니다. 제목, 코드 블록, 이미지의 위치는 단단하게 고정한 채, 그 안의 텍스트 노드(Node) 내용만을 부드럽게 변환하는 것입니다.

우리는 이 시스템을 구현하기 위해 `GPT-4.1`나 `Claude 4.5 Haiku` 같은 가볍고 빠른 모델을 사용하고, 외부 글을 가져오기 위해 `Crawl4AI` 라이브러리를 고민할 것입니다. 어려운 용어 위에 마우스를 올리면 친절하게 설명해주는 'Interactive Glossaries'도 추가하겠죠.

이 모든 기술적 시도 끝에 남는 것은 결국 **'소통'**입니다.