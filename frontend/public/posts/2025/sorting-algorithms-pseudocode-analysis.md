---
title: "정렬 알고리즘 수도 코드 완전 해부: 라인별 분석"
date: "2025-11-02"
category: "알고리즘"
tags: ['정렬', '알고리즘', '수도코드', '학습노트']
excerpt: "버블 정렬부터 힙 정렬까지, 핵심 수도 코드를 한 줄씩 뜯어보며 왜 그런 로직이 필요한지 한국어로 상세하게 분석합니다."
readTime: "18분"
---

## 정렬 알고리즘 수도 코드 완전 해부

기존 글인 《정렬 알고리즘 완전 정복: 버블 정렬부터 힙 정렬까지》(@/home/nodove/workspace/blog/frontend/public/posts/2025/sorting-algorithms-masterclass.md)를 기반으로, 이번에는 **각 알고리즘의 수도 코드 각각의 행이 의미하는 바를 세밀하게 분석**한다. 흐름을 한 눈에 이해하는 것과 별개로, “왜 이 줄이 필요할까?”라는 의문을 해결하는 데 집중했다.

> **읽는 방법**
>
> 1. 먼저 수도 코드를 전체로 살펴보고,
> 2. 곧바로 라인별 해설과 설계상의 이유, 주의할 점을 확인하자.

## 1. 버블 정렬 (Bubble Sort)

### 1-1. 수도 코드

```text
Bubble_Sort(A[], n):
    for i from n-1 down to 1:
        for j from 0 to i-1:
            if (A[j] > A[j+1])
                swap A[j] and A[j+1]
```

### 1-2. 라인별 해설

- `Bubble_Sort(A[], n):`
  - 정렬 대상 배열 `A`와 길이 `n`을 인자로 받는다. 외부에서 배열 복사 없이 **제자리 정렬**을 수행한다는 전제가 깔려 있다.
- `for i from n-1 down to 1:`
  - 바깥 루프는 “이번 라운드에서 끝에 확정될 위치”를 가리킨다. `n-1`에서 시작해 줄어들기 때문에, 이미 정렬된 마지막 구간을 다시 검사하지 않는다.
- `for j from 0 to i-1:`
  - 현재 라운드에서 비교해야 할 구간은 `0`부터 `i-1`까지. `i` 위치에는 앞선 라운드에서 가장 큰 값이 밀려 들어가므로, **불필요한 비교를 줄이는 최적화**다.
- `if (A[j] > A[j+1])`
  - **오름차순 정렬 기준**을 명시한다. 조건을 뒤집으면 내림차순으로도 쉽게 바뀐다.
- `swap A[j] and A[j+1]`
  - 인접한 두 원소를 교체하여 “큰 값이 뒤로 이동”하도록 만든다. 버블 정렬의 핵심 동작이며, 스왑 횟수가 최악인 이유이기도 하다.

### 1-3. 왜 이렇게 설계했을까?

- 인접 비교만 사용하므로 구현이 단순하다.
- 하지만 매 라운드에 최대 한 번의 최댓값만 확정되기 때문에 $O(n^2)$이 불가피하다.
- 조기 종료를 넣고 싶다면 라운드마다 교환 발생 여부를 기록하는 `swapped` 플래그 추가가 일반적이다.

## 2. 선택 정렬 (Selection Sort)

### 2-1. 수도 코드

```text
Selection_Sort(A[], n):
    for i from 0 to n-2:
        minIndex ← i
        for j from i+1 to n-1:
            if (A[j] < A[minIndex])
                minIndex ← j
        swap A[i] and A[minIndex]
```

### 2-2. 라인별 해설

- `Selection_Sort(A[], n):`
  - 배열 전체를 한 번에 책임지는 함수. 입력 검증이나 복사 없이 직접 정렬한다.
- `for i from 0 to n-2:`
  - 현재 라운드에서 “앞으로 보낼” 위치를 지정한다. 마지막 원소는 자동으로 자리가 정해지므로 `n-2`까지만 반복한다.
- `minIndex ← i`
  - 현재 구간에서 발견한 최솟값의 위치를 저장한다. 라운드가 시작될 때는 일단 `i`가 최솟값이라고 가정한다.
- `for j from i+1 to n-1:`
  - 남은 구간을 전부 훑어 진짜 최솟값을 찾는다. 비교 횟수가 항상 $O(n^2)$인 원인이다.
- `if (A[j] < A[minIndex])`
  - 더 작은 값을 만나면 `minIndex` 갱신. 안정성이 떨어지는 이유는 ‘같을 때’는 교환하지 않기 때문이다.
- `minIndex ← j`
  - 최솟값 위치를 최신화한다.
- `swap A[i] and A[minIndex]`
  - 탐색이 끝난 뒤 한 번만 스왑한다. **쓰기 횟수를 줄이는 장점**이 여기서 나온다.

### 2-3. 왜 이렇게 설계했을까?

- 쓰기 비용이 큰 환경에서 유리하다.
- 하지만 비교 횟수가 상당해, 큰 데이터셋에는 부적합하다.
- 안정성을 확보하려면 “선택된 최솟값을 끌어내고 나머지를 한 칸씩 미는” 삽입형 변형이 필요하다.

## 3. 삽입 정렬 (Insertion Sort)

### 3-1. 수도 코드

```text
Insertion_Sort(A[], n):
    for i from 1 to n-1:
        key ← A[i]
        j ← i - 1
        while (j ≥ 0 and A[j] > key):
            A[j + 1] ← A[j]
            j ← j - 1
        A[j + 1] ← key
```

### 3-2. 라인별 해설

- `Insertion_Sort(A[], n):`
  - 삽입 정렬의 메인 함수. 앞쪽 구간이 항상 정렬되어 있다는 **불변식**을 유지한다.
- `for i from 1 to n-1:`
  - 두 번째 원소부터 순차적으로 “손에 든 카드”처럼 처리한다. 첫 번째 원소는 이미 정렬됐다고 본다.
- `key ← A[i]`
  - 현재 삽입할 값을 별도 변수에 저장한다. 뒤로 미는 과정에서 값이 덮어써지는 것을 막는다.
- `j ← i - 1`
  - 정렬된 구간의 마지막 인덱스를 가리킨다.
- `while (j ≥ 0 and A[j] > key):`
  - 정렬된 구간을 거꾸로 탐색하며 적절한 삽입 위치를 찾는다. 조건식에 두 가지 검사를 함께 둬야 **경계와 정렬 조건**을 동시에 만족시킨다.
- `A[j + 1] ← A[j]`
  - 더 큰 값을 한 칸 뒤로 밀어 자리를 비운다. 이 과정 덕분에 안정성을 유지한다.
- `j ← j - 1`
  - 계속 왼쪽으로 이동하면서 비교한다.
- `A[j + 1] ← key`
  - 적절한 위치를 찾거나 배열의 맨 앞을 지나쳤다면, 비워둔 자리(`j+1`)에 키를 삽입한다.

### 3-3. 왜 이렇게 설계했을까?

- 이미 정렬된 구간은 건드리지 않고, 새 원소의 위치만 조정한다.
- 거의 정렬된 입력에서 매우 빠르기 때문에 하이브리드 정렬에서 자주 사용된다.
- `while` 조건 순서를 바꾸면 경계 검사가 늦게 수행돼 오류가 날 수 있다. `j >= 0` 검사를 먼저 두는 것이 안전하다.

## 4. 병합 정렬 (Merge Sort)

### 4-1. Merge 함수 수도 코드

```text
Merge(A[], p, q, r):
    i ← p; j ← q + 1; t ← 0
    while (i ≤ q and j ≤ r):
        if (A[i] < A[j]) tmp[t++] ← A[i++]
        else tmp[t++] ← A[j++]
    while (i ≤ q): tmp[t++] ← A[i++]
    while (j ≤ r): tmp[t++] ← A[j++]
    i ← p; t ← 0
    while (i ≤ r): A[i++] ← tmp[t++]
```

### 4-2. 라인별 해설

- `Merge(A[], p, q, r):`
  - `A[p..q]`와 `A[q+1..r]`가 이미 정렬되었다는 **전제**를 두고, 두 구간을 합쳐 정렬한다.
- `i ← p; j ← q + 1; t ← 0`
  - 왼쪽 구간 포인터 `i`, 오른쪽 구간 포인터 `j`, 그리고 임시 배열 인덱스 `t` 초기화.
- `while (i ≤ q and j ≤ r):`
  - 두 구간 모두에 원소가 남아 있는 동안 병합을 반복한다.
- `if (A[i] < A[j]) tmp[t++] ← A[i++]`
  - 더 작은 값을 임시 배열에 복사하고, 해당 포인터를 이동한다. 안정성을 위해 ‘같음’일 때는 오른쪽이 아닌 왼쪽을 먼저 선택한다.
- `else tmp[t++] ← A[j++]`
  - 오른쪽 구간의 값이 더 작거나 같은 경우를 처리한다.
- `while (i ≤ q): tmp[t++] ← A[i++]`
  - 왼쪽 구간에 남은 원소를 모두 복사한다.
- `while (j ≤ r): tmp[t++] ← A[j++]`
  - 오른쪽 구간에 남은 원소를 모두 복사한다.
- `i ← p; t ← 0`
  - 원본 배열에 결과를 덮어쓸 준비를 위해 인덱스를 재설정한다.
- `while (i ≤ r): A[i++] ← tmp[t++]`
  - 임시 배열 내용을 다시 `A`에 복사한다. **추가 메모리 필요성**이 바로 이 단계에서 비롯된다.

### 4-3. 왜 이렇게 설계했을까?

- 두 정렬 리스트를 선형 시간에 병합하려면 **양쪽 포인터를 동시에 움직이는 방식**이 최선이다.
- 임시 배열을 이용해 정렬된 결과를 안전하게 보관하고, 마지막에 한 번에 덮어쓴다.
- 안정성을 확보하려면 `<=` 대신 `<`를 사용해 왼쪽 선공 우선순위를 지켜야 한다.

## 5. 퀵 정렬 (Quick Sort)

### 5-1. 수도 코드

```text
Quick_Sort(A[], p, r):
    if (p < r):
        q ← partition(A, p, r)
        Quick_Sort(A, p, q - 1)
        Quick_Sort(A, q + 1, r)

partition(A, p, r):
    pivot ← A[r]
    i ← p - 1
    for j from p to r - 1:
        if (A[j] ≤ pivot):
            i ← i + 1
            swap A[i] and A[j]
    swap A[i + 1] and A[r]
    return i + 1
```

### 5-2. 라인별 해설 (Quick_Sort)

- `Quick_Sort(A[], p, r):`
  - 재귀 함수로, 부분 배열 `A[p..r]`를 정렬한다. **분할 정복** 구조의 진입점.
- `if (p < r):`
  - 최소 2개의 원소가 있을 때만 정렬이 필요하다. 재귀 종료 조건.
- `q ← partition(A, p, r)`
  - 분할 함수가 피벗의 최종 위치 `q`를 반환한다. 이 위치의 값은 이후 변경되지 않는다.
- `Quick_Sort(A, p, q - 1)`
  - 피벗보다 작은 부분 배열을 재귀적으로 정렬한다.
- `Quick_Sort(A, q + 1, r)`
  - 피벗보다 큰 부분 배열을 재귀적으로 정렬한다.

### 5-3. 라인별 해설 (partition)

- `partition(A, p, r):`
  - `A[r]`을 피벗으로 삼아 배열을 분할한다. 로무토(Lomuto) 방식.
- `pivot ← A[r]`
  - 마지막 원소를 피벗으로 선택한다. 구현이 단순하지만, 정렬된 데이터에선 불리할 수 있다.
- `i ← p - 1`
  - “피벗 이하 구간”의 끝 인덱스를 의미한다. 아직 아무 원소도 포함되지 않았으므로 시작은 `p-1`.
- `for j from p to r - 1:`
  - 피벗을 제외한 모든 원소를 순회하며 위치를 조정한다.
- `if (A[j] ≤ pivot):`
  - 현재 원소가 피벗 이하라면 왼쪽 구간으로 보내야 한다. `≤` 덕분에 **중복 값이 왼쪽에 몰려 안정성을 흉내내지만, 완전한 안정 정렬은 아니다.**
- `i ← i + 1`
  - 왼쪽 구간의 경계를 한 칸 확장한다.
- `swap A[i] and A[j]`
  - 현재 원소를 왼쪽 구간의 끝으로 이동시킨다. 이미 왼쪽에 있다면 자기 자신과 스왑되어 변화가 없다.
- `swap A[i + 1] and A[r]`
  - 피벗을 왼쪽 구간 다음 위치로 옮겨, **피벗의 최종 위치를 확정**한다.
- `return i + 1`
  - 피벗의 위치를 반환하여 재귀에서 구간을 나누게 한다.

### 5-4. 왜 이렇게 설계했을까?

- 제자리 정렬이 가능해 추가 메모리가 필요 없다.
- 재귀 깊이가 깊어질 수 있으므로, **피벗 선택 전략**(무작위, median-of-three 등)으로 최악의 경우를 회피한다.
- Tail recursion 제거 또는 반복 구현으로 스택 오버플로를 방지하기도 한다.

## 6. 힙 정렬 (Heap Sort)

### 6-1. 핵심 서브루틴 수도 코드

```text
percolateDown(A[], k, n):
    child ← 2k + 1
    while (child ≤ n - 1):
        right ← 2k + 2
        if (right ≤ n - 1 and A[child] < A[right])
            child ← right
        if (A[k] < A[child]):
            swap A[k] and A[child]
            k ← child
            child ← 2k + 1
        else:
            break

deleteMax(A[], n):
    max ← A[0]
    A[0] ← A[n - 1]
    percolateDown(A, 0, n - 1)
    return max
```

### 6-2. 라인별 해설 (percolateDown)

- `percolateDown(A[], k, n):`
  - 최대 힙에서 노드 `k`가 힙 속성을 위반했을 때 아래로 내려보내며 복구한다.
- `child ← 2k + 1`
  - 완전 이진트리에서 왼쪽 자식의 인덱스. 힙은 **배열 기반**이므로 인덱스 계산이 중요하다.
- `while (child ≤ n - 1):`
  - 자식이 존재하는 동안 반복한다. `n`은 힙 크기.
- `right ← 2k + 2`
  - 오른쪽 자식 인덱스 계산.
- `if (right ≤ n - 1 and A[child] < A[right])`
  - 오른쪽 자식이 존재하고 더 크다면, 더 큰 자식을 선택한다. **최대 힙 유지의 핵심**.
- `child ← right`
  - 비교 대상으로 오른쪽 자식을 지정한다.
- `if (A[k] < A[child]):`
  - 부모가 더 작다면 힙 속성이 깨진 것이므로 교환이 필요하다.
- `swap A[k] and A[child]`
  - 부모와 더 큰 자식을 교환해 힙 조건을 복구한다.
- `k ← child`
  - 내려간 위치에서 다시 검사를 이어가기 위해 현재 노드를 갱신한다.
- `child ← 2k + 1`
  - 새 위치에서 왼쪽 자식 인덱스를 다시 계산한다.
- `else: break`
  - 부모가 이미 더 크거나 자식이 없으면 힙 속성이 만족되어 루프 종료.

### 6-3. 라인별 해설 (deleteMax)

- `deleteMax(A[], n):`
  - 힙 정렬에서 최대값을 추출하는 동작. 정렬 루프의 한 단계와 동일하다.
- `max ← A[0]`
  - 힙의 루트가 항상 최댓값이므로 결과로 저장한다.
- `A[0] ← A[n - 1]`
  - 마지막 원소를 루트로 올려 힙 크기를 줄인다.
- `percolateDown(A, 0, n - 1)`
  - 루트에서 다시 힙 속성을 복구한다.
- `return max`
  - 추출된 최댓값을 반환한다. 힙 정렬에서는 이 값을 배열 끝에 배치하는 방식으로 사용한다.

### 6-4. 왜 이렇게 설계했을까?

- 완전 이진트리 구조 덕분에 배열 인덱스로 부모/자식 관계를 계산할 수 있다.
- 추출 후 힙 복구까지 $O(\log n)$이 보장되어, 전체 정렬이 $O(n \log n)$이 된다.
- 메모리가 제한된 환경에서 일관된 성능을 제공한다.

## 7. 마무리

이번 글에서는 여섯 가지 대표 정렬 알고리즘의 수도 코드를 **한 줄 단위로 파헤치며 설계 의도를 해석**했다. 원리를 이해하면 다음과 같은 장점이 있다.

1. 구현을 변형하거나 최적화를 추가할 때 실수를 줄일 수 있다.
2. 시간 복잡도 분석이 직관적으로 이해된다.
3. 디버깅 시 어떤 줄이 문제를 일으키는지 빠르게 파악할 수 있다.

정렬은 다른 알고리즘의 하위 루틴으로 자주 쓰이므로, 이번 정리가 더 복잡한 주제(예: TimSort, IntroSort, 외부 정렬 등)를 학습할 때 든든한 발판이 되길 바란다.
