---
title: "알고리즘 수업 노트를 다시 펼쳐 보며"
date: "2025-10-19"
category: "Computer Science"
tags: ['알고리즘', '복잡도', '분할정복', '동적계획법', '탐욕법']
excerpt: "기초 알고리즘 수업 노트를 다시 펼쳐 보며..."
readTime: "8분"
---

알고리즘이라는 단어를 처음 들었을 때, 저는 그냥 "코드 짜는 순서" 정도로 생각했습니다. 그런데 학부 시절 기초 알고리즘 강의를 들으면서, 이게 단순한 절차가 아니라 문제 해결의 철학이라는 사실을 깨달았어요. 문제를 정의하고, 풀어낼 방법을 설명하고, 그게 진짜 맞는지 증명하고, 얼마나 빠르고 가벼운지 분석하는 과정. 그때 비로소 컴퓨터과학이 수학과 공학 사이 어디쯤에 서 있는 학문이라는 감각이 왔습니다. 요즘은 이 노트를 꺼내 놓고 글을 쓰다 보면, 그 시절의 설렘과 두려움이 함께 솟구칩니다.

### 알고리즘을 바라보는 기준선

알고리즘이 알고리즘다우려면 몇 가지 기본을 갖춰야 한다는 이야기를 처음 들었을 때를 기억합니다. 입력과 출력이 있는지, 절차가 애매하지 않은지, 언젠가는 반드시 멈출지, 사람이 연필과 종이로도 흉내 낼 만큼 단순한 명령으로 이루어져 있는지 말이죠. 특히 "유한성"이라는 조건을 듣고는 잠깐 멍해졌어요. 운영체제처럼 늘 켜져 있어야 하는 소프트웨어는 엄격한 의미의 알고리즘이 아니라는 말이 새삼 낯설었거든요. 하지만 곰곰이 생각해 보니, 우리는 결국 끝이 보장되는 문제 해결법을 연구하고 있었고, 그게 계산 가능성의 가장 단단한 토대였습니다.

### 측정하고 또 측정하기

취업 준비하면서 제일 많이 외웠던 단어는 아마도 "빅오(Big-O)"였던 것 같습니다. 직접 실행 시간을 재면 하드웨어와 컴파일러에 따라 숫자가 바뀌니, 입력 크기 `n`에 따른 연산 횟수를 세는 쪽이 더 믿을 만하다는 그 말이 아직도 생생합니다. 그리고 점근적 분석이라는 말을 처음 접했을 때, 문제를 끝까지 밀어붙이면 결국 `n`이 무한히 커졌을 때의 모습을 보게 된다는 발상이 무척 멋졌죠. O(1)에서 O(2^n)까지 줄줄 외우던 순서가 단순한 암기가 아니라, "엔지니어는 최악의 상황을 놓치지 않는다"는 철학이라는 걸 깨닫고 나서는, 복잡도 표기법이 갑자기 인간적인 언어로 느껴졌습니다.

### 세 가지 단골 패러다임과의 동행

알고리즘 수업의 절반은 분할 정복, 동적 계획법, 탐욕법에 대한 이야기였던 것 같습니다. 분할 정복은 큰 문제를 쪼개고 재귀적으로 풀어 다시 합치는 하향식(top-down) 사고를 가르쳐 주었습니다. 병합 정렬과 퀵 정렬이 왜 그렇게 우아하게 작동하는지 이해하고 나니, 배열을 반으로 갈라서 다시 합치는 단순한 생각이 얼마나 강력한지 실감했죠.

동적 계획법(DP)을 처음 이해했을 때는 진짜 기쁨에 소리를 질렀습니다. 피보나치 수열을 예로 들면, 서로 다른 분기에서 같은 하위 문제를 반복해서 푸는 것이 시간 낭비라는 걸 깨닫는 순간이 있잖아요. 그때 메모이제이션을 붙여 주면 곧장 선형 시간이 됩니다. "중복되는 하위 문제"와 "최적 부분 구조"라는 키워드가 제 공부 노트에 가장 많이 등장했던 이유죠. 분할 정복과의 차이를 물어보는 시험 문제에도, 저는 항상 "하위 문제가 겹치는가?"라는 한 줄 메모를 해 두곤 했습니다.

탐욕 알고리즘은 또 다른 세계였습니다. 매 순간 가장 좋아 보이는 선택을 하는 것이 결국 전체를 최적으로 만든다는 것, 그걸 증명하는 과정이 얼마나 어려운지 직접 겪고 나서야 알았거든요. 다익스트라나 크루스칼 알고리즘이 왜 그렇게 단순한 전략으로도 멋진 결과를 내는지 이해하려면, 탐욕적 선택 속성과 최적 부분 구조를 수식으로 잡아 줘야 했습니다. 이게 어쩌면 가장 엔지니어다운 사고 아닐까요? 완벽한 해답보다, 현실적인 시간 안에 쓸 만한 해답을 보장하는 전략. 제게 탐욕법은 그런 실용적 낙관주의를 가르쳐 준 선생님 같은 존재였습니다.

### 정렬과 탐색이라는 기본기

정렬 알고리즘 표를 외우던 밤도 빠질 수 없습니다. 버블, 선택, 삽입 정렬은 느리지만 구조가 단순해서, 데이터가 거의 정렬된 상황에서는 삽입 정렬이 얼마나 빠르게 변신하는지 직접 코딩하며 느꼈죠. 이후에 만난 병합 정렬과 퀵 정렬, 힙 정렬은 `O(n log n)`이라는 공통점을 공유하면서도, 추가 공간과 최악의 경우에 대한 서로 다른 타협을 제시했습니다. 학부생 시절의 저는 이 차이를 정리한 표를 책상 위에 붙여 놓고, 각 알고리즘의 안정성과 제자리성 여부까지 꼼꼼히 외우곤 했습니다.

탐색 알고리즘을 이해하면서는 "정렬된 데이터가 있다는 가정이 얼마나 큰 힘인지"를 절감했습니다. 선형 탐색은 누구나 떠올릴 수 있지만, 이진 탐색이 `O(log n)`으로 데이터를 찾아내는 모습을 보고 나서는, 정렬이 단순한 미관이 아니라 성능 자체에 대한 투자라는 것을 마음에 새겼습니다. 제가 만든 첫 프로젝트에서 이진 탐색을 잘못 구현해 버그를 고치던 날, "왼쪽과 오른쪽 경계가 만나는 순간"을 다르게 처리해 놓은 제 코드가 멈춰있던 화면이 아직도 눈에 선합니다.

### 그래프 위를 걷다

입사 준비를 하면서 DFS와 BFS를 외우는 일은 이제 일종의 통과의례가 됐습니다. DFS를 재귀로 구현할 때마다 호출 스택이 암묵적인 스택 자료구조가 된다는 말이 실감났고, BFS로 가중치 없는 그래프에서 최단 경로를 찾을 때 큐가 얼마나 단단한 도구인지 깨달았습니다. 더 나아가 다익스트라는 단순한 탐욕 알고리즘이 아닌 우선순위 큐 기반의 고급 전략이라는 걸 이해했고, 벨만-포드가 음수 가중치까지 처리하며 음수 사이클까지 잡아낸다는 사실에 또 한 번 감탄했죠.

최소 신장 트리를 공부하면서는 크루스칼과 프림이 서로 다른 관점에서 같은 목표를 향해 달려간다는 점이 인상적이었습니다. 하나는 간선 중심, 다른 하나는 정점 중심. 그런데 두 알고리즘 모두 "사이클을 만들지 않는 가장 싸고 좋은 연결"이라는 직관을 공유합니다. 희소 그래프와 밀집 그래프에 따라 더 적합한 알고리즘이 분리된다는 사실은, 문제를 제대로 파악하는 일이 해결 방법만큼이나 중요하다는 것을 다시 일깨워 줬습니다.

### 실전에서 만난 알고리즘

일상에서 가장 자주 떠올렸던 예시는 A* 알고리즘이었습니다. 길 찾기를 하면서 다익스트라에 휴리스틱을 더해 목적지 방향으로 탐색을 우선시하는 그 방식, 바로 현실적인 타협이죠. 완벽한 최단 경로를 보장하면서도 실제 지리 정보를 활용해 속도를 끌어올리는 아이디어. 이게 바로 정형 알고리즘과 경험적 지식이 손을 잡을 때 얼마나 아름다운 결과가 나오는지 보여줍니다.

웹 검색 엔진의 페이지랭크를 공부할 때도 그랬습니다. 링크를 투표로 보는 관점, 그리고 그 투표에 가중치를 두는 방식은 네트워크를 그래프로 모델링하는 사고의 극치였죠. 추천 시스템의 콘텐트 기반 필터링과 협업 필터링을 비교하면서는 "데이터가 없으면 아무것도 할 수 없다"는 콜드 스타트 문제의 현실을 배웠습니다.

머신러닝을 접하면서는 알고리즘이 갑자기 낡은 교과서 속의 이야기가 아니라, 데이터 압축과 해싱, 그래프 순회 같은 실전 도구로 다시 살아났습니다. K-평균 군집화가 사실상 데이터 압축의 한 형태라는 말이 새삼 와 닿았습니다. 기본기를 튼튼히 다지는 일이 결국 새로운 분야의 밑거름이 된다는 걸, 몇 번이고 확인했습니다.

### 앞으로도 계속 이어질 질문들

이렇게 돌아보면, 알고리즘을 공부한다는 건 그냥 코딩 스킬을 쌓는 일이 아니라 사고방식을 다듬는 과정이었습니다. 문제를 명확히 정의하고, 더 나은 방식을 끊임없이 찾고, 때때로 최악의 경우를 대비해 차분하게 시스템을 설계하는 태도. 빅데이터와 분산 시스템, 머신러닝이 아무리 새로운 무기를 들고 와도, 결국 복잡도 분석과 데이터 구조 선택이라는 기본 원칙은 여전히 변치 않는 나침반이 되어 줍니다.

이제는 새로운 프로젝트를 시작할 때마다, 저는 묻습니다. "이 문제의 구조는 무엇인가?", "하위 문제들은 서로 겹치는가?", "탐욕적인 선택이 통할까?" 그리고 "최악의 경우에도 시스템이 버틸까?" 이 질문들은 처음 누군가에게 배워서 적어 놓았던 강의 노트의 문장들인데, 이제는 제 사고방식 그 자체가 되어 버렸습니다. 어쩌면 알고리즘 공부가 제게 남겨 준 가장 큰 선물은, 이 질문들을 평생 동안 반복하게 만들었다는 사실인지도 모릅니다.
