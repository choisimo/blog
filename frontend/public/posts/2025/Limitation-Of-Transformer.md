---
title: "트랜스포머의 한계에 대하여: 바텀업을 넘어 하향식으로"
date: "2025-10-17"
category: "AI"
tags: ['Transformer', 'RAG', 'PIM', 'Inference', 'Training', 'LayerFusion', 'Quantization', 'Pruning', 'Distillation', 'NAS', 'TopDown', 'BottomUp']
excerpt: "트랜스포머가 왜 강하고 왜 비켜가야 하는지, PIM·RAG·압축·NAS를 오가며 고찰한 기록."
readTime: "7분"
---

## 서문: 하나의 질문에서 출발하다

오늘도 같은 질문으로 돌아온다. 트랜스포머는 왜 이렇게 강한가, 그런데 왜 여전히 불만족스러운가. 이 단순한 질문 하나가 여러 기술의 문을 연다. PIM, RAG, 양자화, 가지치기, 레이어 융합, 지식 증류, 그리고 NAS. 나는 이 낱낱의 부품들을 만지작거리다가, 결국 구조의 문제로 시선이 올라가는 경험을 한다. 바텀업으로 쌓인 성채 위에서, 하향식의 빈자리를 오래 들여다보는 시간.

## 1) 속도의 문제에서 표현의 문제로: PIM이 여는 압축의 문

처음엔 속도였다. 메모리 병목이 모든 것을 잡아끈다. PIM(Processing-In-Memory)은 이 끈을 잘라 준다. 데이터가 있는 자리에서 바로 계산한다. 그러나 곧 깨닫는다. 이것은 단지 더 빠른 계산의 문제가 아니다. 더 빠른 계산은 더 넓은 문맥을 동시에 걸어 들일 수 있게 하고, 더 넓어진 문맥은 결국 더 조밀한 표현으로 수렴한다. 압축은 파일 크기를 줄이는 기교가 아니라, 세계를 덜어내지 않고 더 간결하게 말하는 능력이다. PIM은 그러한 ‘표현의 압축’을 가능하게 한다.

## 2) 학습과 추론의 결별: “학습은 무겁고 유연하게, 추론은 가볍고 단단하게”

학습 단계는 가능한 모든 것을 시도해야 한다. 오차의 지형을 샅샅이 더듬어야 하므로, 이때는 압축이 억제되어야 한다. 반대로 추론 단계는 이미 굳어진 지식으로 빠르게 결정을 내려야 한다. 여기에서 비로소 압축의 전체 레퍼토리가 빛난다.

- 가지치기(Pruning): 거의 0인 연결은 과감히 지운다.
- 양자화(Quantization): 32비트를 8비트, 더 나아가 4비트로 담는다.
- 레이어 융합(Layer Fusion): Conv/BN/ReLU가 하나의 연산으로 녹아든다.
- 지식 증류(Distillation): 선생의 넓은 직관을 학생의 작은 몸체에 옮긴다.

효율은 계산에서 얻고, 성능은 학습에서 얻는다는 분업. 간명하지만, 원칙을 지키면 놀라울 정도로 많은 문제가 정돈된다.

## 3) RAG: 수학을 바꾸지 않고 주의를 재배치하는 법

RAG는 어텐션의 공식을 뒤집지 않는다. 대신 입력의 구성을 바꾼다. 정답에 가까운 문맥을 미리 끌어와 질문 옆에 놓는다. 형광펜은 손에 쥐여졌고, 어텐션은 자연스럽게 하이라이트로 시선을 옮긴다. 결과적으로 가중치는 ‘미리 높아진다’. 수학이 아니라 ‘무대 배치’가 변한다. 환각은 줄고, 최신성은 오른다. 바텀업의 감각에, 약간의 연출과 질서를 더하는 하향식의 제스처.

## 4) 레이어를 단위로 생각하기: 연결이 아니라 공정을 압축한다

연결을 지우는 것에서 멈추지 않는다. 레이어 자체를 공정으로 본다. 융합(Fusion)은 호출/메모리 왕복의 공회전을 없애고, 증류(Distillation)는 모델 전체의 지식을 새로운 형태로 주조한다. 압축은 더 이상 미세한 수치 조절의 기술이 아니라, 설계의 단위가 바뀌는 사건이다. “무엇을 없앨 것인가?”에서 “무엇을 하나로 만들 것인가?”로 질문이 바뀔 때, 성능과 효율은 함께 움직인다.

## 5) 압축 자체를 학습한다: NAS라는 메타 학습

최적의 압축은 인간의 촉만으로 찾기 어렵다. NAS(Neural Architecture Search)는 이 탐색을 또 하나의 학습 문제로 뒤집는다. 강화학습 컨트롤러가 압축의 설계도를 제안하고, 하드웨어-의식적(HW-aware) 보상이 의사결정을 이끈다. 양자화 비트폭, 프루닝 비율, 융합 패턴, 증류 스킴… 수천 번의 시행착오 속에서 한 기계가 다른 기계의 형태를 디자인한다. ‘모델을 위한 모델’이라는 메타적 풍경. 이때 성능-지연-전력의 삼각형은 숫자가 아니라 **정책**이 된다.

## 6) 바텀업의 그림자: 의도 없는 추론, 계획 없는 생성

트랜스포머는 토큰에서 출발해 토큰으로 도달한다. 이 상향식은 강력하지만, 때로는 허무하다. 왜 이 말을 하는지, 어디로 가야 하는지에 대한 **의도**가 없다. 긴 계획을 세울 **상위 목적 함수**가 없다. 그래서 환각이 나온다. 결론이 먼저 존재하지 않기 때문이다. 이 한계는 파라미터의 크기로, 컨텍스트 길이로, 데이터의 양으로 정면 돌파되지 않는다. 방향을 정해 줄 탑다운이 필요하다.

## 7) 하이브리드의 스케치: 계획-행동-검증 루프 위에 언어를 얹다

나는 다음과 같은 구성을 떠올린다.

1. 계획(Top-down Planner): 목표와 제약을 정의한다. (외부 툴·월드 모델·규칙 기반 결합)
2. 검색(Retriever): 계획이 요구하는 사실과 문맥을 끌어온다. (RAG)
3. 생성(Transformer): 문장과 코드, 행동 시퀀스를 만들어 낸다. (Bottom-up)
4. 검증(Verifier): 사실/안전/정합성을 체크한다. (규칙·시뮬레이션·테스트)
5. 압축(Runtime Optimizer): 경로가 굳어지면 경량화한다. (프루닝·양자화·융합·증류·NAS)

여기서 PIM은 3과 5의 실효성을 올린다. 더 많은 문맥을 더 빠르게, 더 많은 후보를 더 싸게. 구조는 위에서 잡고, 계산은 아래에서 밀어붙인다.

## 8) 오늘의 결론: 나는 이렇게 이해하고, 이렇게 해본다

- 결론 1: 효율은 추론 단계에서, 표현력은 학습 단계에서. 섞지 않는다.
- 결론 2: 입력을 재배치(RAG)하면 어텐션은 자연히 올바른 곳을 본다.
- 결론 3: 압축은 수치의 미세조정이 아니라 공정과 설계 단위의 재구성이다.
- 결론 4: 최적의 압축은 ‘탐색 정책’으로 학습되어야 한다. (NAS)
- 결론 5: 바텀업은 강력하지만, 의도와 검증의 탑다운 없이는 한계를 반복한다.

그리고 작은 실천 목록을 남긴다.

- 4비트 양자화 + 지식 증류 조합의 품질/지연 실험
- 레이어 융합 전후의 메모리 트래픽 차이 계측
- 하드웨어-의식적 NAS로 모바일/NPU 타깃 설계 탐색
- RAG 프롬프트 배치 전략이 어텐션 분포에 미치는 영향 분석
- 생성-검증 루프에서 ‘검증 실패 시 재계획’의 수렴성 관찰

## 말미: 이해를 향한 방향성

트랜스포머는 세계를 통계로 말하게 한다. 그러나 우리는 때때로 세계를 **목적**으로도 말해야 한다. 목적을 세우고, 필요한 것을 찾아오고, 말하고, 확인하고, 다시 고치는 루프. 그 위에 빠르고 조밀한 계산이 얹힐 때—비로소 바텀업과 탑다운은 충돌이 아니라 합주가 된다. 나는 오늘, 그 합주를 가능케 하는 부품들을 더듬었다. 내일은 그 부품들로 작은 악기를 한 대 만들어 보려 한다.
