---
title: "Understanding State Space Models and Mamba"
date: "2026-01-17"
category: "AI"
tags: ["SSM", "Mamba", "Architecture", "DeepLearning", "Transformer", "Math"]
excerpt: "Transformer의 대안으로 떠오르는 SSM과 Mamba의 원리를 깊이 있게 설명합니다. 인지 과학적 은유부터 Induction Heads 메커니즘까지."
readTime: "12분"
---

혹시 그런 상상을 해보신 적 있나요? 수백 페이지짜리 소설책을 읽는데, 새로운 문장을 읽을 때마다 앞서 읽었던 모든 내용을 토씨 하나 틀리지 않고 처음부터 다시 떠올려야 한다면 어떨까요. 아마 머리가 터져버릴 겁니다. 아이러니하게도, 지금 전 세계를 휩쓸고 있는 Transformer 모델들이 바로 그런 방식으로 작동합니다. 문장이 길어질수록 계산량은 기하급수적으로 늘어나고(O(N²)), 메모리는 비명을 지르죠. "더 긴 문맥, 더 많은 데이터"를 외치는 시대에 이 무거움은 생각보다 큰 족쇄가 되고 있습니다.

그래서 엔지니어들은 다시 기본으로 돌아갔습니다. "과거의 모든 디테일을 짊어지고 가는 대신, 핵심만 요약해서 주머니에 넣고 가면 안 될까?" 이 단순하고도 강력한 아이디어를 실현하기 위해, 제어 공학의 오래된 서랍 속에 있던 **SSM(State Space Model, 상태 공간 모델)**을 꺼내 들었습니다.

![alt text](image.png)

오늘은 이 고전적인 도구가 어떻게 최신 AI의 심장이 되었는지, 그 원리를 바닥부터 천천히 짚어보려 합니다.

## 두 개의 SSM: 뇌과학과 딥러닝 사이

본론으로 들어가기 전에, 잠시 용어의 지도를 펼쳐봐야 합니다. 'SSM'이라는 단어는 사실 학문 분야마다 조금씩 다른 사투리로 쓰이거든요.

만약 여러분이 계산 뇌과학(Computational Neuroscience) 연구자라면, SSM이라는 단어를 듣고 **동적 인과 모델링(Dynamic Causal Modeling, DCM)**을 떠올렸을 겁니다. 뇌 영역 간의 활성도나 연결성이 어떻게 변하는지를 통계적으로 추론할 때 쓰는 도구죠.

하지만 오늘 우리가 다룰 SSM은 딥러닝의 세계, 정확히는 **구조화된 상태 공간 모델(Structured SSMs, S4)**입니다. 뇌의 생물학적 유사성을 분석하는 것이 아니라, 텍스트나 오디오 같은 시퀀스 데이터를 어떻게 하면 RNN처럼 효율적이면서도 CNN처럼 빠르게 처리할 수 있을까를 고민한 결과물입니다. 아이러니하게도, 인간의 기억 방식을 흉내 내려는 공학적 시도가 뇌과학과는 또 다른 독자적인 진화를 이뤄낸 셈이죠.

## 기억의 방정식: 시스템의 뼈대

가장 먼저 이 시스템의 뼈대가 되는 방정식부터 살펴보죠. 겁먹을 필요는 없습니다. 생각보다 단순하거든요. SSM은 시간이 흐름에 따라 변화하는 '상태(State)'를 수학적으로 모델링 합니다.

```math
h'(t) = Ah(t) + Bx(t)
y(t) = Ch(t) + Dx(t)
```

이 식을 가만히 들여다보면 각 알파벳이 맡은 역할이 보입니다. 여기서 $h(t)$는 현재의 '상태'입니다. 과거의 모든 정보를 압축해서 담고 있는 요약본이죠. $x(t)$는 지금 막 들어온 '입력'이고요.

가장 중요한 건 행렬 **A**입니다. 이것은 *State Matrix*라고 불리는데, 이전의 상태를 얼마나 잊지 않고 유지할지를 결정합니다. **B**는 *Input Matrix*로, 새로운 입력이 상태에 얼마나 영향을 줄지 결정하는 문지기입니다. 마지막으로 **C**는 내부 상태를 우리가 볼 수 있는 결과값 $y(t)$로 변환해 줍니다.

결국 이 식의 본질은 **"현재의 상태는 과거의 요약($Ah(t)$)과 새로운 자극($Bx(t)$)의 합"**이라는 것입니다. 이것이 SSM이 Transformer와 달리, 입력 길이가 늘어나도 계산량이 선형적(O(N))으로만 늘어나는 비결입니다. 과거를 다 들고 다니는 게 아니라, $h(t)$라는 고정된 가방 하나만 들고 다니니까요.

## Mamba의 진화: 선택적 기억 (Selection Mechanism)

하지만 초기 SSM(S4 등)에는 치명적인 단점이 있었습니다. 행렬 A, B, C가 모든 입력에 대해 **고정(Time-invariant)**되어 있었거든요. 마치 "모든 손님에게 똑같은 톤으로 인사하는 로봇" 같았습니다. 중요한 정보든 잡음이든 똑같이 처리하니, 맥락에 따라 중요도를 조절하는 유연함이 부족했죠.

이 답답함을 해결하기 위해 등장한 것이 바로 **Mamba**입니다. Mamba의 핵심 아이디어는 **선택적 메커니즘(Selection Mechanism)**입니다.

Mamba는 입력값 $x_t$의 내용이 무엇이냐에 따라 행렬 $B$, $C$, 그리고 시간 간격 $\Delta$가 실시간으로 변합니다.

*   **중요한 정보가 들어오면:** $\Delta$를 키웁니다. 마치 "이건 중요하니까 굵게 밑줄 쫙!" 하는 것처럼 정보를 상태 $h_t$에 깊이 각인시킵니다.
*   **쓸데없는 내용(Noise)이 들어오면:** $\Delta$를 작게 줄여, 상태가 오염되지 않도록 사실상 **Gating(차단)** 합니다.

이것은 인지 과학적으로 볼 때, 인간이 대화 중 "음...", "어..." 같은 불필요한 추임새는 흘려듣고 핵심 단어만 귀담아듣는 집중력과 매우 닮아 있습니다.

## 유도 헤드(Induction Heads)와 연관 회상

그렇다면 이 '선택적 메커니즘'으로 Mamba는 무엇을 할 수 있게 되었을까요? 여기서 **유도 헤드(Induction Heads)**라는 흥미로운 개념이 등장합니다. 이것은 LLM이 맥락을 이해하는 핵심 능력인 **'연관 회상(Associative Recall)'**을 설명하는 메커니즘입니다.

쉽게 예를 들어보죠. 우리가 책을 읽다가 "Harry"라는 단어를 봤습니다. 만약 앞부분에서 "Harry Potter"라는 단어 쌍을 본 적이 있다면, 우리 뇌는 자연스럽게 다음 단어로 "Potter"를 기대합니다. 이것이 바로 연관 회상입니다. 과거의 맥락(Context)을 뒤져서 현재와 유사한 패턴을 찾아내고, 그 뒤에 무엇이 왔는지를 **'복사(Copy)'**해 오는 것이죠.

기존의 SSM은 이 능력이 부족했습니다. 정보를 너무 꾹꾹 눌러 담다 보니, "Harry 뒤에 Potter가 왔었나?" 하는 구체적인 세부 사항이 뭉개져 버렸거든요. 하지만 Mamba는 선택적 메커니즘을 통해 중요한 토큰(Harry) 주변의 정보를 선명하게 남겨둡니다.

덕분에 Mamba는 학습한 길이보다 무려 4000배나 더 긴, 100만 토큰 길이의 시퀀스에서도 이 '연관성'을 놓치지 않습니다. Transformer가 거대한 주의(Attention) 행렬을 만들어 모든 단어 쌍을 비교하며 찾아내는 바로 그 능력을, Mamba는 아주 작은 상태 공간 안에서 효율적으로 해내는 것입니다.

## 마치며: 효율적인 지능을 향하여

결국 SSM과 Mamba가 우리에게 보여주는 것은 '효율적인 기억'에 대한 오래된 지혜입니다. 모든 것을 하나하나 다 기억하려 애쓰는(Transformer) 대신, 흐름을 읽고 중요하지 않은 것은 과감히 흘려보내는(Mamba) 것.

물론 이것이 뇌의 작동 원리와 완벽히 같다고 할 수는 없습니다. 하지만 불필요한 정보를 걸러내고(Filtering), 중요한 과거 패턴을 불러와(Induction Heads) 현재를 예측하는 그 방식만큼은, 인간의 지능이 가진 효율성을 구현해 낸 것이 아닐까 생각듭니다.
