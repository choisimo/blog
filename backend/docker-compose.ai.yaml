# NoAICode Docker Compose - OpenAI SDK Compatible AI Server
# 
# 사용법:
#   기본 (serve + backend + redis): docker compose up -d
#   serve만:                        docker compose up -d noaicode
#   backend만 (원격 연결):           docker compose --profile backend-only up -d backend-standalone
#   nginx 인증 포함:                docker compose --profile auth up -d
#   Cloudflare Tunnel 포함:         docker compose --profile auth --profile tunnel up -d
#
# OpenAI SDK 호환 엔드포인트:
#   - Base URL: http://<host>:7016/v1
#   - Chat Completions: POST /v1/chat/completions
#   - Models: GET /v1/models
#   - Embeddings: POST /v1/embeddings
#
# 환경변수 (.env 파일 또는 export):
#   GITHUB_REPOSITORY_OWNER   - GHCR 이미지 소유자 (기본: choisimo)
#   NOAICODE_SERVE_TAG        - noaicode-serve 이미지 태그 (기본: latest)
#   BACKEND_TAG               - noaicode-backend 이미지 태그 (기본: latest)
#   NGINX_TAG                 - ai-server-nginx 이미지 태그 (기본: latest)
#   NOAICODE_BASE_URL         - 원격 NoAICode 서버 URL (backend-only 프로필용)
#   CLOUDFLARE_TUNNEL_TOKEN   - Cloudflare Tunnel 토큰 (tunnel 프로필용)
#   AUTH_ENABLED              - API Key 인증 활성화 (기본: true)
#   ADMIN_MASTER_KEY          - Admin API 마스터 키 (미설정시 자동 생성됨)
#   AI_API_KEY                - OpenAI SDK 호환 API Key (GitHub Secrets에서 관리)
#
# GitHub Secrets 연동:
#   배포 시 다음 secrets가 .env 파일로 주입됩니다:
#   - AI_API_KEY              → ADMIN_MASTER_KEY로 사용
#   - AI_SERVER_URL           → 외부 접근 URL (선택)

services:
  # ============================================================
  # Redis (Rate Limiting & Session Storage)
  # ============================================================
  redis:
    image: redis:7-alpine
    restart: unless-stopped
    command: redis-server --appendonly yes --maxmemory 128mb --maxmemory-policy allkeys-lru
    volumes:
      - redis-data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 3
      start_period: 5s
    security_opt:
      - no-new-privileges:true

  # ============================================================
  # NoAICode Serve (OpenCode AI Server)
  # ============================================================
  noaicode:
    image: ghcr.io/${GITHUB_REPOSITORY_OWNER:-choisimo}/ai-server-serve:${NOAICODE_SERVE_TAG:-latest}
    pull_policy: always
    restart: unless-stopped
    ports:
      - "${NOAICODE_PORT:-7015}:7012"
    environment:
      NODE_ENV: production
      NOAICODE_HOST: 0.0.0.0
      NOAICODE_PORT: 7012
    volumes:
      - noaicode-data:/home/appuser/.local/share/opencode
      - noaicode-logs:/var/log/opencode
    healthcheck:
      test: ["CMD-SHELL", "node -e \"const http=require('http'); http.get('http://localhost:7012/app', ()=>process.exit(0)).on('error', ()=>process.exit(1));\""]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 10s
    security_opt:
      - no-new-privileges:true

  # ============================================================
  # NoAICode Backend (API Server) - OpenAI SDK Compatible
  # Provides /v1/chat/completions, /v1/models, /v1/embeddings
  # ============================================================
  backend:
    image: ghcr.io/${GITHUB_REPOSITORY_OWNER:-choisimo}/ai-server-backend:${BACKEND_TAG:-latest}
    pull_policy: always
    restart: unless-stopped
    ports:
      - "${BACKEND_PORT:-7016}:7016"
    environment:
      PORT: 7016
      NODE_ENV: production
      NOAICODE_BASE_URL: http://noaicode:7012
      DEFAULT_PROVIDER: ${DEFAULT_PROVIDER:-github-copilot}
      DEFAULT_MODEL: ${DEFAULT_MODEL:-gpt-4.1}
      FALLBACK_PROVIDER: ${FALLBACK_PROVIDER:-opencode}
      FALLBACK_MODEL: ${FALLBACK_MODEL:-big-pickle}
      ENABLE_CHAT_UI: ${ENABLE_CHAT_UI:-false}
      SYSTEM_PROMPT: ${SYSTEM_PROMPT:-}
      # OpenAI SDK Compatible Settings
      OPENAI_COMPAT_ENABLED: "true"
      # Authentication (API Key from GitHub Secrets)
      AUTH_ENABLED: ${AUTH_ENABLED:-true}
      ADMIN_MASTER_KEY: ${AI_API_KEY:-${ADMIN_MASTER_KEY:-}}
      # Rate Limiting
      REDIS_ENABLED: "true"
      REDIS_URL: redis://redis:6379
      DEFAULT_RPM: ${DEFAULT_RPM:-60}
      DEFAULT_TPM: ${DEFAULT_TPM:-100000}
      DEFAULT_RPD: ${DEFAULT_RPD:-10000}
      # Storage
      STORAGE_TYPE: json
      STORAGE_PATH: /app/data
    volumes:
      - backend-data:/app/data
    depends_on:
      noaicode:
        condition: service_healthy
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "wget -q -O- http://127.0.0.1:7016/health || exit 1"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 10s
    security_opt:
      - no-new-privileges:true

  # ============================================================
  # Backend Only (원격 NoAICode 서버 연결용)
  # docker compose --profile backend-only up -d backend-standalone
  # ============================================================
  backend-standalone:
    profiles:
      - backend-only
    image: ghcr.io/${GITHUB_REPOSITORY_OWNER:-choisimo}/ai-server-backend:${BACKEND_TAG:-latest}
    pull_policy: always
    restart: unless-stopped
    ports:
      - "${BACKEND_PORT:-7016}:7016"
    environment:
      PORT: 7016
      NODE_ENV: production
      NOAICODE_BASE_URL: ${NOAICODE_BASE_URL:-https://ai.nodove.com}
      ENABLE_CHAT_UI: ${ENABLE_CHAT_UI:-true}
      SYSTEM_PROMPT: ${SYSTEM_PROMPT:-}
      # Authentication
      AUTH_ENABLED: ${AUTH_ENABLED:-true}
      ADMIN_MASTER_KEY: ${ADMIN_MASTER_KEY:-}
      # Rate Limiting (in-memory without Redis)
      REDIS_ENABLED: "false"
      DEFAULT_RPM: ${DEFAULT_RPM:-60}
      DEFAULT_TPM: ${DEFAULT_TPM:-100000}
      DEFAULT_RPD: ${DEFAULT_RPD:-10000}
      # Storage
      STORAGE_TYPE: json
      STORAGE_PATH: /app/data
    volumes:
      - backend-data:/app/data
    healthcheck:
      test: ["CMD-SHELL", "wget -q -O- http://127.0.0.1:7016/health || exit 1"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 10s
    security_opt:
      - no-new-privileges:true

  # ============================================================
  # Nginx Reverse Proxy (인증/보안용)
  # docker compose --profile auth up -d
  # ============================================================
  nginx:
    profiles:
      - auth
    image: ghcr.io/${GITHUB_REPOSITORY_OWNER:-choisimo}/ai-server-nginx:${NGINX_TAG:-latest}
    pull_policy: always
    restart: unless-stopped
    depends_on:
      noaicode:
        condition: service_healthy
      backend:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "test -f /var/run/nginx.pid && kill -0 $(cat /var/run/nginx.pid)"]
      interval: 10s
      timeout: 3s
      retries: 10
      start_period: 5s
    security_opt:
      - no-new-privileges:true

  # ============================================================
  # Cloudflare Tunnel
  # docker compose --profile auth --profile tunnel up -d
  # ============================================================
  cloudflared:
    profiles:
      - tunnel
    image: cloudflare/cloudflared:latest
    restart: unless-stopped
    command:
      - tunnel
      - --no-autoupdate
      - run
      - --token
      - ${CLOUDFLARE_TUNNEL_TOKEN}
    environment:
      TUNNEL_URL: http://nginx:80
    depends_on:
      nginx:
        condition: service_healthy
    security_opt:
      - no-new-privileges:true

volumes:
  noaicode-data:
    driver: local
  noaicode-logs:
    driver: local
  redis-data:
    driver: local
  backend-data:
    driver: local