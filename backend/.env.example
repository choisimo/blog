# Application (prefer root .env; this file is optional override)
APP_ENV=development
HOST=0.0.0.0
PORT=5080
TRUST_PROXY=1
LOG_LEVEL=info

# Origins and URLs
SITE_BASE_URL=https://noblog.nodove.com
API_BASE_URL=http://localhost:5080
ALLOWED_ORIGINS=https://noblog.nodove.com,http://localhost:8080,http://localhost:5173

# Rate limiting
RATE_LIMIT_MAX=60
RATE_LIMIT_WINDOW_MS=60000

# =============================================================================
# AI Provider Configuration
# =============================================================================
# Which AI provider to use: 'litellm' (recommended), 'vas', or 'gemini'
# If not set, auto-detects based on available configuration
AI_PROVIDER=litellm

# =============================================================================
# LiteLLM AI Gateway (Recommended - Single endpoint for all AI providers)
# =============================================================================
# Master key for authenticating with LiteLLM proxy
LITELLM_MASTER_KEY=sk-litellm-your-secret-key
# LiteLLM endpoint (Docker internal)
LITELLM_BASE_URL=http://litellm:4000
# Default model to use
AI_DEFAULT_MODEL=gpt-4.1

# Provider API Keys (used by LiteLLM)
# Only fill in the providers you want to use
OPENAI_API_KEY=
GOOGLE_API_KEY=
ANTHROPIC_API_KEY=

# =============================================================================
# Aidove Webhook (n8n RAG/Agent Pipeline)
# =============================================================================
# n8n webhook URL for Aidove AI workflows
# When configured, enables aidove/aidove-rag models in LiteLLM
AIDOVE_WEBHOOK_URL=https://workflow.nodove.com/webhook/aidove
# RAG-specific webhook (uses separate n8n workflow with vector search)
# If not set, RAG requests fall back to basic webhook
AIDOVE_RAG_WEBHOOK_URL=https://workflow.nodove.com/webhook/aidove-rag
# Optional: API key for webhook authentication
AIDOVE_API_KEY=
# Optional: Request timeout in ms (default: 120000)
AIDOVE_WEBHOOK_TIMEOUT=120000

# VAS (GitHub Copilot) API endpoint
AI_SERVE_BASE_URL=http://ai-serve:7012/v1
# VAS API Key (auto-generated from vas-bootstrap)
# Usually read from file: /app/shared/auto-token.jwt
VAS_API_KEY=

# =============================================================================
# Legacy: Direct Gemini (deprecated - use LiteLLM instead)
# =============================================================================
GEMINI_API_KEY=
GEMINI_MODEL=gemini-1.5-flash

# Cloudflare D1 (for comments/analytics/translate/personas/memos)
# Get these from Cloudflare Dashboard
CF_ACCOUNT_ID=f6f11e2a4e5178d2f37476785018f761
CF_API_TOKEN=
D1_DATABASE_ID=e547f944-71a0-42b6-8af1-abc50f29df80

# Cloudflare R2 (for image storage)
# Uses same CF_ACCOUNT_ID and CF_API_TOKEN as D1
R2_BUCKET_NAME=blog
R2_ASSETS_BASE_URL=https://assets-b.nodove.com

# Firebase (deprecated - use D1 instead)
# Put the full JSON string of your service account here (escaped as a single line), or use Docker/K8s secrets.
FIREBASE_SERVICE_ACCOUNT_JSON=
FIREBASE_PROJECT_ID=

# GitHub for Admin PR creation
GITHUB_TOKEN=
GITHUB_REPO_OWNER=choisimo
GITHUB_REPO_NAME=blog
GIT_USER_NAME=CI Bot
GIT_USER_EMAIL=ci@example.com

# Admin token for protected routes (Bearer <token>)
ADMIN_BEARER_TOKEN=

# Optional: JWT auth for admin login
JWT_SECRET=
ADMIN_USERNAME=
ADMIN_PASSWORD=
